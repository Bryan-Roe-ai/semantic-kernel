# Semantic Kernel Python Environment Configuration
# Copy this file to .env and fill in your actual values
# DO NOT COMMIT .env TO VERSION CONTROL

# =============================================================================
# REQUIRED: AI SERVICE PROVIDERS (Choose One)
# =============================================================================

# Option 1: OpenAI (Recommended for getting started)
OPENAI_API_KEY=""
OPENAI_ORG_ID=""
OPENAI_CHAT_MODEL_ID="gpt-4o-mini"
OPENAI_TEXT_MODEL_ID="gpt-3.5-turbo-instruct" 
OPENAI_EMBEDDING_MODEL_ID="text-embedding-3-small"

# Option 2: Azure OpenAI (Enterprise preferred)
AZURE_OPENAI_ENDPOINT=""
AZURE_OPENAI_API_KEY=""
AZURE_OPENAI_API_VERSION="2024-06-01"
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=""
AZURE_OPENAI_TEXT_DEPLOYMENT_NAME=""
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=""

# Global service selection: "openai" or "azure_openai"
GLOBAL_LLM_SERVICE="openai"

# =============================================================================
# OPTIONAL: VECTOR STORES & SEARCH
# =============================================================================

# Azure AI Search (recommended for production)
AZURE_AI_SEARCH_ENDPOINT=""
AZURE_AI_SEARCH_API_KEY=""
AZURE_AI_SEARCH_INDEX_NAME="semantic-kernel-index"
AZURE_AI_SEARCH_SERVICE=""

# Pinecone (popular cloud vector database)
PINECONE_API_KEY=""
PINECONE_ENVIRONMENT=""

# Weaviate (open source vector database)
WEAVIATE_URL=""
WEAVIATE_API_KEY=""

# Redis (for caching and vector storage)
REDIS_CONNECTION_STRING=""

# =============================================================================
# OPTIONAL: DATABASES
# =============================================================================

# MongoDB Atlas (for document storage)
MONGODB_ATLAS_CONNECTION_STRING=""

# PostgreSQL (for relational data)
POSTGRES_CONNECTION_STRING=""

# Azure Cosmos DB (NoSQL database)
AZCOSMOS_CONNSTR=""
AZCOSMOS_DATABASE_NAME=""
AZCOSMOS_CONTAINER_NAME=""

# AstraDB (Cassandra-based)
ASTRADB_APP_TOKEN=""
ASTRADB_ID=""
ASTRADB_REGION=""
ASTRADB_KEYSPACE=""

# =============================================================================
# OPTIONAL: SEARCH & WEB SERVICES
# =============================================================================

# Google Custom Search (for web search capabilities)
GOOGLE_SEARCH_ENGINE_ID=""
GOOGLE_API_KEY=""

# Brave Search API (privacy-focused search)
BRAVE_API_KEY=""

# SerpAPI (search engine results)
SERPAPI_KEY=""

# =============================================================================
# OPTIONAL: ADDITIONAL AI SERVICES
# =============================================================================

# Hugging Face (for open source models)
HF_ACCESS_TOKEN=""

# CrewAI (for multi-agent workflows)
CREW_AI_ENDPOINT=""
CREW_AI_TOKEN=""

# Azure Content Safety (for content moderation)
AZURE_CONTENT_SAFETY_ENDPOINT=""
AZURE_CONTENT_SAFETY_API_KEY=""

# =============================================================================
# OPTIONAL: AZURE SERVICES
# =============================================================================

# Azure Container Apps
ACA_POOL_MANAGEMENT_ENDPOINT=""

# Azure Key Vault
KEY_VAULT_ENDPOINT=""

# Azure Blob Storage
AZURE_BLOB_STORAGE_ENDPOINT=""

# Azure Cognitive Services
AZURE_COGNITIVE_SERVICES_ENDPOINT=""

# =============================================================================
# OPTIONAL: SAMPLE-SPECIFIC CONFIGURATIONS
# =============================================================================

# Microsoft Booking Sample (for booking demos)
BOOKING_SAMPLE_CLIENT_ID=""
BOOKING_SAMPLE_TENANT_ID=""
BOOKING_SAMPLE_CLIENT_SECRET=""
BOOKING_SAMPLE_BUSINESS_ID=""
BOOKING_SAMPLE_SERVICE_ID=""

# =============================================================================
# OPTIONAL: LOCAL AI (For offline/self-hosted models)
# =============================================================================

# Ollama (local LLM runtime)
OLLAMA_ENDPOINT="http://localhost:11434"
OLLAMA_MODEL="llama3.2"

# Text Generation Inference (HuggingFace TGI)
TGI_ENDPOINT="http://localhost:8080"

# Local LLM endpoint
LOCAL_LLM_ENDPOINT="http://localhost:8080"
LOCAL_LLM_MODEL=""

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================

# Logging and debugging
DEBUG="false"
LOG_LEVEL="INFO"
PYTHONPATH="${PYTHONPATH}:."

# Test configuration
TEST_TIMEOUT="30000"
TEST_RETRIES="3"
